{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T10:24:33.201666Z",
     "start_time": "2020-12-17T10:24:33.193784Z"
    }
   },
   "outputs": [],
   "source": [
    "domains = ['photo', 'art_painting', 'cartoon', 'sketch']\n",
    "classes = ['dog', 'elephant', 'giraffe', 'guitar', 'horse','house', 'person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T10:24:34.799832Z",
     "start_time": "2020-12-17T10:24:33.210174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "import torchvision.datasets as Datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "#Modify\n",
    "from utils_byol_training import *\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model selection\n",
    "from model.resnet_original import resnet18\n",
    "from model.feature_mixer import Feature_mixer\n",
    "\n",
    "\n",
    "#BYOL 관련 Import\n",
    "import argparse\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "from byol.byol_pytorch import BYOL\n",
    "from utils.utils_byol import *\n",
    "import copy\n",
    "\n",
    "\n",
    "##############################\n",
    "# Training Setting\n",
    "##############################\n",
    "used_model = 'resnet18'  # 'resnet18' or 'resnet18_classic'\n",
    "dataset ='pacs'\n",
    "save_name = 'pacs_byol'\n",
    "pacs_ver = 'pacs_official_split' # 'pacs_official_unseen' or 'pacs_official_split'\n",
    "number_of_tests = 1\n",
    "\n",
    "##############################\n",
    "# BYOL Hyper-parameters\n",
    "##############################\n",
    "\n",
    "byol_batch_size = 128\n",
    "byol_epochs     = 1 # 원래 100\n",
    "byol_lr         = 3e-4\n",
    "byol_image_size = 224\n",
    "# byol_num_gps   = 1\n",
    "# byol_image_exts = ['.jpg', '.png', '.jpeg']\n",
    "# byol_num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "#byol conv layer freeze 하고 linear layer 학습할지 여부\n",
    "is_byol_conv_freeze=False\n",
    "\n",
    "##############################\n",
    "# Fine-tune Hyper-parameters\n",
    "##############################\n",
    "training_setting = 'byol' # 'classic' or 'di' or 'cc'(and di) or 'fm' or 'byol'\n",
    "epochs = [1]\n",
    "batch_size = 128\n",
    "is_pretrained = True\n",
    "is_domain_vec = False\n",
    "is_dc = False\n",
    "color_jitter = True\n",
    "\n",
    "lr = 1e-4\n",
    "lr_decay_epoch = [10000]\n",
    "lr_decay_gamma = 0.5\n",
    "gamma_d_loss = 0.5\n",
    "entropy_weight = 0.5\n",
    "gpu_num = 0\n",
    "\n",
    "\n",
    "device= torch.device('cpu')\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")\n",
    "    device = torch.device(\"cuda:{}\".format(gpu_num))\n",
    "print(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "#Modify\n",
    "train_tf, test_tf = get_tf(color_jitter, augment=True)\n",
    "\n",
    "#추가 : byol  관련 파라미터 \n",
    "#모델 세팅 저장 \n",
    "model_settings={\n",
    "    \"used_model\" : used_model,\n",
    "    \"dataset\" : dataset,\n",
    "    \"save_name\" : save_name,\n",
    "    \"pacs_ver\" : pacs_ver,\n",
    "    \"number_of_tests\" : number_of_tests,\n",
    "    \"training_setting\" : training_setting,\n",
    "    \"epochs\" : epochs,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"is_pretrained\" : is_pretrained,\n",
    "    \"is_domain_vec\" : is_domain_vec,\n",
    "    \"is_dc\" : is_dc,\n",
    "    \"color_jitter\" : color_jitter,\n",
    "    \"lr\" : lr,\n",
    "    \"lr_decay_epoch\" : lr_decay_epoch,\n",
    "    \"lr_decay_gamma\" : lr_decay_gamma,\n",
    "    \"gamma_d_loss\" : gamma_d_loss,\n",
    "    \"entropy_weight\" : entropy_weight,\n",
    "    \"gpu_num\" : gpu_num\n",
    "}\n",
    "\n",
    "if training_setting==\"byol\":\n",
    "    model_settings['byol_batch_size']=byol_batch_size\n",
    "    model_settings['byol_epochs']=byol_epochs\n",
    "    model_settings['byol_lr']=byol_lr\n",
    "    model_settings['byol_image_size']=byol_image_size\n",
    "    model_settings['is_byol_conv_freeze']=is_byol_conv_freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T10:24:34.983021Z",
     "start_time": "2020-12-17T10:24:34.802602Z"
    },
    "code_folding": [
     52,
     130,
     254
    ]
   },
   "outputs": [],
   "source": [
    "def classic_setting(test_domain_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model,pacs_ver):\n",
    "    \n",
    "    train_set1 = ImageFolder(root=os.path.join('{}/train'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+1)%len(domains)]), transform = train_tf)\n",
    "    train_set2 = ImageFolder(root=os.path.join('{}/train'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+2)%len(domains)]), transform = train_tf)\n",
    "    train_set3 = ImageFolder(root=os.path.join('{}/train'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+3)%len(domains)]), transform = train_tf)\n",
    "        \n",
    "    val_set1 = ImageFolder(root=os.path.join('{}/val'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+1)%len(domains)]), transform = test_tf)\n",
    "    val_set2 = ImageFolder(root=os.path.join('{}/val'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+2)%len(domains)]), transform = test_tf)\n",
    "    val_set3 = ImageFolder(root=os.path.join('{}/val'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+3)%len(domains)]), transform = test_tf)\n",
    "    \n",
    "    train_set = train_set1+train_set2+train_set3\n",
    "    val_set = val_set1+val_set2+val_set3\n",
    "    test_set = ImageFolder(root=os.path.join('{}/test'.format(pacs_ver),domains[test_domain_idx]), transform = test_tf)\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "    \n",
    "    if used_model=='vgg16':\n",
    "        print('vgg16')\n",
    "        model = models.vgg16(pretrained=is_pretrained).cuda()\n",
    "        model.classifier[6].out_features=7\n",
    "    elif used_model=='inceptionv3':\n",
    "        model = models.inception_v3(pretrained=is_pretrained).cuda()\n",
    "        model.AuxLogits.fc.out_features = 7\n",
    "        model.fc.out_features=7\n",
    "    elif used_model=='resnet18':\n",
    "        # load weights pretrained on ImageNet\n",
    "        model = resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,len(classes))\n",
    "        model = model.to(device)\n",
    "    elif used_model=='resnet18_classic':\n",
    "        model = models.resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,len(classes))\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_decay_epoch, gamma= lr_decay_gamma)  \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, optimizer, model, scheduler\n",
    "\n",
    "def di_setting(test_domain_idx,domains, batch_size, is_pretrained, train_tf, test_tf, used_model,pacs_ver):\n",
    "    domain_photo = torch.tensor([1.,0.,0.,0.,0.])\n",
    "    domain_art_painting = torch.tensor([0.,1.,0.,0.,0.])\n",
    "    domain_cartoon = torch.tensor([0.,0.,1.,0.,0.])\n",
    "    domain_sketch = torch.tensor([0.,0.,0.,1.,0.])\n",
    "    unseen_domain = torch.tensor([0.,0.,0.,0.,1.])\n",
    "    domain_list=[domain_art_painting,domain_cartoon,domain_photo,domain_sketch]\n",
    "    \n",
    "    train_set1 = DGImageFolder(domain=domain_list[(test_domain_idx+1)%len(domains)],\n",
    "                               root=os.path.join('{}/train'.format(pacs_ver),domains[(test_domain_idx+1)%len(domains)]),\n",
    "                               transform = train_tf)\n",
    "    train_set2 = DGImageFolder(domain=domain_list[(test_domain_idx+2)%len(domains)],\n",
    "                               root=os.path.join('{}/train'.format(pacs_ver),domains[(test_domain_idx+2)%len(domains)]),\n",
    "                               transform = train_tf)\n",
    "    train_set3 = DGImageFolder(domain=domain_list[(test_domain_idx+3)%len(domains)],\n",
    "                               root=os.path.join('{}/train'.format(pacs_ver),domains[(test_domain_idx+3)%len(domains)]),\n",
    "                               transform = train_tf)\n",
    "    \n",
    "    unseen_train_set_1=DGImageFolder(domain=unseen_domain, \n",
    "                                     root=os.path.join('{}/train/unseen'.format(pacs_ver),domains[(test_domain_idx+1)%len(domains)]),\n",
    "                                     transform = train_tf)\n",
    "    unseen_train_set_2=DGImageFolder(domain=unseen_domain, \n",
    "                                     root=os.path.join('{}/train/unseen'.format(pacs_ver),domains[(test_domain_idx+2)%len(domains)]),\n",
    "                                     transform = train_tf)\n",
    "    unseen_train_set_3=DGImageFolder(domain=unseen_domain, \n",
    "                                     root=os.path.join('{}/train/unseen'.format(pacs_ver),domains[(test_domain_idx+3)%len(domains)]),\n",
    "                                     transform = train_tf)\n",
    "    \n",
    "    train_set = train_set1+train_set2+train_set3+unseen_train_set_1+unseen_train_set_2+unseen_train_set_3\n",
    "    \n",
    "    val_set1 = DGImageFolder(domain=domain_list[(test_domain_idx+1)%len(domains)],\n",
    "                               root=os.path.join('{}/val'.format(pacs_ver),domains[(test_domain_idx+1)%len(domains)]),\n",
    "                               transform = test_tf)\n",
    "    val_set2 = DGImageFolder(domain=domain_list[(test_domain_idx+2)%len(domains)],\n",
    "                               root=os.path.join('{}/val'.format(pacs_ver),domains[(test_domain_idx+2)%len(domains)]),\n",
    "                               transform = test_tf)\n",
    "    val_set3 = DGImageFolder(domain=domain_list[(test_domain_idx+3)%len(domains)],\n",
    "                               root=os.path.join('{}/val'.format(pacs_ver),domains[(test_domain_idx+3)%len(domains)]),\n",
    "                               transform = test_tf)\n",
    "    \n",
    "    val_set = val_set1 + val_set2 + val_set3\n",
    "    \n",
    "    test_set = DGImageFolder(domain=unseen_domain, root=os.path.join('{}/test'.format(pacs_ver),domains[test_domain_idx]), transform = test_tf)\n",
    "    \n",
    "    print(len(train_set),len(val_set), len(test_set))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=6,\n",
    "                             drop_last=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=6)\n",
    "    \n",
    "    if used_model=='vgg16':\n",
    "        print('vgg16')\n",
    "        model = models.vgg16(pretrained=is_pretrained).to(device)\n",
    "        model.classifier[6].out_features=7\n",
    "    elif used_model=='inceptionv3':\n",
    "        model = models.inception_v3(pretrained=is_pretrained).to(device)\n",
    "        model.AuxLogits.fc.out_features = 7\n",
    "        model.fc.out_features=7\n",
    "    elif used_model=='resnet18':\n",
    "        # load weights pretrained on ImageNet\n",
    "        model = resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,7)\n",
    "        model = model.to(device)\n",
    "    elif used_model=='resnet18_classic':\n",
    "        model = models.resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,7)\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[lr_decay_epoch], gamma= lr_decay_gamma)  \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, optimizer, model,scheduler\n",
    "\n",
    "def cc_setting(test_domain_idx,domains, batch_size, is_pretrained, train_tf, test_tf, used_model,pacs_ver):\n",
    "    \n",
    "    domain_art_painting = torch.tensor([1.,0.,0.,0.,0.])\n",
    "    domain_cartoon = torch.tensor([0.,1.,0.,0.,0.])\n",
    "    domain_photo = torch.tensor([0.,0.,1.,0.,0.])\n",
    "    domain_sketch = torch.tensor([0.,0.,0.,1.,0.])\n",
    "    unseen_domain = torch.tensor([0.,0.,0.,0.,1.])\n",
    "    domain_list = [domain_photo, domain_art_painting, domain_cartoon, domain_sketch]\n",
    "    \n",
    "    \n",
    "    check = 1\n",
    "    train_set = 0\n",
    "    val_set = 0\n",
    "    check_limit = 2\n",
    "    \n",
    "    for i in range(4):\n",
    "        if check > check_limit:\n",
    "            break\n",
    "        if i==test_domain_idx:\n",
    "            continue\n",
    "        \n",
    "        temp = DGImageFolder(domain=domain_list[i],\n",
    "                           root=os.path.join('{}/train'.format(pacs_ver),domains[i]),\n",
    "                           transform = train_tf)\n",
    "        temp_unseen = DGImageFolder(domain=unseen_domain, \n",
    "                             root=os.path.join('{}/train/unseen'.format(pacs_ver),domains[i]),\n",
    "                             transform = train_tf)\n",
    "        temp_val = DGImageFolder(domain=domain_list[i],\n",
    "                               root=os.path.join('{}/val'.format(pacs_ver),domains[i]),\n",
    "                               transform = test_tf)\n",
    "        if check==1:\n",
    "            train_set = temp\n",
    "            val_set = temp_val\n",
    "        else:\n",
    "            train_set += temp\n",
    "            val_set += temp_val\n",
    "        \n",
    "        train_set += temp_unseen\n",
    "        check += 1\n",
    "    \n",
    "    train_set_stage1 = train_set\n",
    "    val_set_stage1 = val_set\n",
    "    \n",
    "    \n",
    "    #이것만 학습에 들어감 \n",
    "    check = 1\n",
    "    train_set = 0\n",
    "    val_set = 0\n",
    "    check_limit = 3\n",
    "    \n",
    "    for i in range(4):\n",
    "        if check > check_limit:\n",
    "            break\n",
    "        if i==test_domain_idx:\n",
    "            continue\n",
    "        \n",
    "        temp = DGImageFolder(domain=domain_list[i],\n",
    "                           root=os.path.join('{}/train'.format(pacs_ver),domains[i]),\n",
    "                           transform = train_tf)\n",
    "        temp_unseen = DGImageFolder(domain=unseen_domain, \n",
    "                             root=os.path.join('{}/train/unseen'.format(pacs_ver),domains[i]),\n",
    "                             transform = train_tf)\n",
    "        temp_val = DGImageFolder(domain=unseen_domain,\n",
    "                               root=os.path.join('{}/val'.format(pacs_ver),domains[i]),\n",
    "                               transform = test_tf)\n",
    "        if check==1:\n",
    "            train_set = temp\n",
    "            val_set = temp_val\n",
    "        else:\n",
    "            train_set += temp\n",
    "            val_set += temp_val\n",
    "        \n",
    "        train_set += temp_unseen\n",
    "        check += 1\n",
    "    \n",
    "    train_set_stage2 = train_set\n",
    "    val_set_stage2 = val_set\n",
    "\n",
    "\n",
    "                             \n",
    "\n",
    "    \n",
    "    test_set = DGImageFolder(domain=unseen_domain, root=os.path.join('{}/test'.format(pacs_ver),domains[test_domain_idx]), transform = test_tf)\n",
    "    \n",
    "    print('stage1 :',len(train_set_stage1),len(val_set_stage1), len(test_set))\n",
    "    print('stage2 :',len(train_set_stage2),len(val_set_stage2), len(test_set))\n",
    "    \n",
    "    train_loader_stage1 = DataLoader(train_set_stage1, batch_size=batch_size, shuffle=True, num_workers=6,\n",
    "                             drop_last=True)\n",
    "    val_loader_stage1 = DataLoader(val_set_stage1, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "    \n",
    "    train_loader_stage2 = DataLoader(train_set_stage2, batch_size=batch_size, shuffle=True, num_workers=6,\n",
    "                             drop_last=True)\n",
    "    val_loader_stage2 = DataLoader(val_set_stage2, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "    \n",
    "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=6)\n",
    "    \n",
    "    if used_model=='vgg16':\n",
    "        print('vgg16')\n",
    "        model = models.vgg16(pretrained=is_pretrained).to(device)\n",
    "        model.classifier[6].out_features=7\n",
    "    elif used_model=='inceptionv3':\n",
    "        model = models.inception_v3(pretrained=is_pretrained).to(device)\n",
    "        model.AuxLogits.fc.out_features = 7\n",
    "        model.fc.out_features=7\n",
    "    elif used_model=='resnet18':\n",
    "        # load weights pretrained on ImageNet\n",
    "        model = resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,7)\n",
    "        model = model.to(device)\n",
    "    elif used_model=='resnet18_classic':\n",
    "        model = models.resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,7)\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[lr_decay_epoch], gamma= lr_decay_gamma)  \n",
    "    \n",
    "    return train_loader_stage1,train_loader_stage2, val_loader_stage1, val_loader_stage2, test_loader, optimizer, model,scheduler\n",
    "\n",
    "def fm_setting(test_domain_idx,domains, batch_size, is_pretrained, train_tf, test_tf, used_model,pacs_ver):\n",
    "#     domain_photo = torch.tensor([1.,0.,0.,0.,0.])\n",
    "#     domain_art_painting = torch.tensor([0.,1.,0.,0.,0.])\n",
    "#     domain_cartoon = torch.tensor([0.,0.,1.,0.,0.])\n",
    "#     domain_sketch = torch.tensor([0.,0.,0.,1.,0.])\n",
    "#     unseen_domain = torch.tensor([0.,0.,0.,0.,1.])\n",
    "#     domain_list=[domain_photo,domain_art_painting,domain_cartoon,domain_sketch]\n",
    "    \n",
    "#     train_set1 = DGImageFolder(domain=domain_list[(test_domain_idx+1)%len(domains)],\n",
    "#                                root=os.path.join('{}/train'.format(pacs_ver),domains[(test_domain_idx+1)%len(domains)]),\n",
    "#                                transform = train_tf)\n",
    "#     train_set2 = DGImageFolder(domain=domain_list[(test_domain_idx+2)%len(domains)],\n",
    "#                                root=os.path.join('{}/train'.format(pacs_ver),domains[(test_domain_idx+2)%len(domains)]),\n",
    "#                                transform = train_tf)\n",
    "#     train_set3 = DGImageFolder(domain=domain_list[(test_domain_idx+3)%len(domains)],\n",
    "#                                root=os.path.join('{}/train'.format(pacs_ver),domains[(test_domain_idx+3)%len(domains)]),\n",
    "#                                transform = train_tf)\n",
    "\n",
    "    \n",
    "#     train_set = train_set1+train_set2+train_set3\n",
    "    \n",
    "#     val_set1 = DGImageFolder(domain=domain_list[(test_domain_idx+1)%len(domains)],\n",
    "#                                root=os.path.join('{}/val'.format(pacs_ver),domains[(test_domain_idx+1)%len(domains)]),\n",
    "#                                transform = test_tf)\n",
    "#     val_set2 = DGImageFolder(domain=domain_list[(test_domain_idx+2)%len(domains)],\n",
    "#                                root=os.path.join('{}/val'.format(pacs_ver),domains[(test_domain_idx+2)%len(domains)]),\n",
    "#                                transform = test_tf)\n",
    "#     val_set3 = DGImageFolder(domain=domain_list[(test_domain_idx+3)%len(domains)],\n",
    "#                                root=os.path.join('{}/val'.format(pacs_ver),domains[(test_domain_idx+3)%len(domains)]),\n",
    "#                                transform = test_tf)\n",
    "    \n",
    "#     val_set = val_set1 + val_set2 + val_set3\n",
    "    \n",
    "#     test_set = DGImageFolder(domain=unseen_domain, root=os.path.join('{}/test'.format(pacs_ver),domains[test_domain_idx]), transform = test_tf)\n",
    "    \n",
    "#     print(len(train_set),len(val_set), len(test_set))\n",
    "    \n",
    "#     train_loader_stage1 = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=6,drop_last=True)\n",
    "#     train_loader_stage2 = DataLoader(train_set, batch_size=batch_size-int(batch_size/4), shuffle=True, num_workers=6, drop_last=True)\n",
    "#     val_loader_stage1 = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=6, drop_last=True)\n",
    "#     val_loader_stage2 = DataLoader(val_set, batch_size=batch_size-int(batch_size/4), shuffle=True, num_workers=6,drop_last=True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=6)\n",
    "\n",
    "    domain_photo = torch.tensor([1.,0.,0.,0.,0.])\n",
    "    domain_art_painting = torch.tensor([0.,1.,0.,0.,0.])\n",
    "    domain_cartoon = torch.tensor([0.,0.,1.,0.,0.])\n",
    "    domain_sketch = torch.tensor([0.,0.,0.,1.,0.])\n",
    "    unseen_domain = torch.tensor([0.,0.,0.,0.,1.])\n",
    "    domain_list = [domain_photo,domain_art_painting,domain_cartoon,domain_sketch]\n",
    "    \n",
    "    \n",
    "    check = 1\n",
    "    train_set = 0\n",
    "    val_set = 0\n",
    "    check_limit = 2\n",
    "    \n",
    "    for i in range(4):\n",
    "        if check > check_limit:\n",
    "            break\n",
    "        if i==test_domain_idx:\n",
    "            continue\n",
    "        \n",
    "        temp = DGImageFolder(domain=domain_list[i],\n",
    "                           root=os.path.join('{}/train'.format(pacs_ver),domains[i]),\n",
    "                           transform = train_tf)\n",
    "        temp_val = DGImageFolder(domain=unseen_domain,\n",
    "                               root=os.path.join('{}/val'.format(pacs_ver),domains[i]),\n",
    "                               transform = test_tf)\n",
    "        if check==1:\n",
    "            train_set = temp\n",
    "            val_set = temp_val\n",
    "        else:\n",
    "            train_set += temp\n",
    "            val_set += temp_val\n",
    "        \n",
    "        check += 1\n",
    "    \n",
    "    train_set_stage1 = train_set\n",
    "    val_set_stage1 = val_set\n",
    "    \n",
    "    \n",
    "    check = 1\n",
    "    train_set = 0\n",
    "    val_set = 0\n",
    "    check_limit = 3\n",
    "    \n",
    "    for i in range(4):\n",
    "        if check > check_limit:\n",
    "            break\n",
    "        if i==test_domain_idx:\n",
    "            continue\n",
    "        \n",
    "        temp = DGImageFolder(domain=domain_list[i],\n",
    "                           root=os.path.join('{}/train'.format(pacs_ver),domains[i]),\n",
    "                           transform = train_tf)\n",
    "        temp_val = DGImageFolder(domain=unseen_domain,\n",
    "                               root=os.path.join('{}/val'.format(pacs_ver),domains[i]),\n",
    "                               transform = test_tf)\n",
    "        if check==1:\n",
    "            train_set = temp\n",
    "            val_set = temp_val\n",
    "        else:\n",
    "            train_set += temp\n",
    "            val_set += temp_val\n",
    "        \n",
    "        check += 1\n",
    "    \n",
    "    train_set_stage2 = train_set\n",
    "    val_set_stage2 = val_set\n",
    "\n",
    "\n",
    "    test_set = DGImageFolder(domain=unseen_domain, root=os.path.join('{}/test'.format(pacs_ver),domains[test_domain_idx]), transform = test_tf)\n",
    "    \n",
    "    print('stage1 :',len(train_set_stage1),len(val_set_stage1), len(test_set))\n",
    "    print('stage2 :',len(train_set_stage2),len(val_set_stage2), len(test_set))\n",
    "    \n",
    "    train_loader_stage1 = DataLoader(train_set_stage1, batch_size=batch_size-int(batch_size/4), shuffle=True, num_workers=6,\n",
    "                             drop_last=True)\n",
    "    val_loader_stage1 = DataLoader(val_set_stage1, batch_size=batch_size, shuffle=True, num_workers=6,drop_last=True)\n",
    "    \n",
    "    train_loader_stage2 = DataLoader(train_set_stage2, batch_size=batch_size-int(batch_size/4), shuffle=True, num_workers=6,\n",
    "                             drop_last=True)\n",
    "    val_loader_stage2 = DataLoader(val_set_stage2, batch_size=batch_size, shuffle=True, num_workers=6,drop_last=True)\n",
    "    \n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "\n",
    "    if used_model=='vgg16':\n",
    "        print('vgg16')\n",
    "        model = models.vgg16(pretrained=is_pretrained).to(device)\n",
    "        model.classifier[6].out_features=7\n",
    "    elif used_model=='inceptionv3':\n",
    "        model = models.inception_v3(pretrained=is_pretrained).to(device)\n",
    "        model.AuxLogits.fc.out_features = 7\n",
    "        model.fc.out_features=7\n",
    "    elif used_model=='resnet18':\n",
    "        # load weights pretrained on ImageNet\n",
    "        model = resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,len(classes))\n",
    "        model = model.to(device)\n",
    "    elif used_model=='resnet18_classic':\n",
    "        model = models.resnet18(pretrained=is_pretrained)        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs,len(classes))\n",
    "        model = model.to(device)\n",
    "    elif used_model=='alexnet':\n",
    "        model = alexnet(pretrained=is_pretrained) \n",
    "        model.classifier[-1]= nn.Linear(4096,len(classes))\n",
    "        model = model.to(device)\n",
    "    elif used_model=='alexnet_classic':\n",
    "        model = models.alexnet(pretrained=is_pretrained) \n",
    "        model.classifier[-1]= nn.Linear(4096,len(classes))\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    mixer = Feature_mixer().to(device)\n",
    "        \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    fm_optimizer = optim.Adam(mixer.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[lr_decay_epoch], gamma= lr_decay_gamma)  \n",
    "    \n",
    "    return train_loader_stage1, train_loader_stage2 , val_loader_stage1, val_loader_stage2, test_loader, optimizer, fm_optimizer, model, mixer, scheduler\n",
    "\n",
    "def byol_setting(test_domain_idx, domains, batch_size, is_pretrained):\n",
    "    \n",
    "    train_loaders=dict()\n",
    "    \n",
    "    for c in classes:\n",
    "        #setting\n",
    "        train_set1 = ImagesDataset(os.path.join('{}/train'.format(pacs_ver),\n",
    "                                                   domains[(test_domain_idx+1)%len(domains)],c),byol_image_size)\n",
    "        train_set2 = ImagesDataset(os.path.join('{}/train'.format(pacs_ver),\n",
    "                                                   domains[(test_domain_idx+2)%len(domains)],c),byol_image_size)\n",
    "        train_set3 = ImagesDataset(os.path.join('{}/train'.format(pacs_ver),\n",
    "                                                   domains[(test_domain_idx+3)%len(domains)],c),byol_image_size)\n",
    "\n",
    "        train_set = train_set1+train_set2+train_set3\n",
    "        \n",
    "        #NUM_WORKERS 변경 \n",
    "        for i in range (2):\n",
    "            train_loaders[c+\"_\"+str(i)] = DataLoader(train_set, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "    \n",
    "    \n",
    "    if used_model=='resnet18':\n",
    "        # load weights pretrained on ImageNet\n",
    "        print(\"여부\",is_pretrained)\n",
    "        model = resnet18(pretrained=is_pretrained)        \n",
    "    elif used_model=='resnet18_classic':\n",
    "        model = models.resnet18(pretrained=is_pretrained)        \n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "     \n",
    "    return model,train_loaders\n",
    "\n",
    "def byol_classic_setting(model,test_domain_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model,pacs_ver):\n",
    "    \n",
    "    train_set1 = ImageFolder(root=os.path.join('{}/train'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+1)%len(domains)]), transform = train_tf)\n",
    "    train_set2 = ImageFolder(root=os.path.join('{}/train'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+2)%len(domains)]), transform = train_tf)\n",
    "    train_set3 = ImageFolder(root=os.path.join('{}/train'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+3)%len(domains)]), transform = train_tf)\n",
    "        \n",
    "    val_set1 = ImageFolder(root=os.path.join('{}/val'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+1)%len(domains)]), transform = test_tf)\n",
    "    val_set2 = ImageFolder(root=os.path.join('{}/val'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+2)%len(domains)]), transform = test_tf)\n",
    "    val_set3 = ImageFolder(root=os.path.join('{}/val'.format(pacs_ver),\n",
    "                                               domains[(test_domain_idx+3)%len(domains)]), transform = test_tf)\n",
    "    \n",
    "    train_set = train_set1+train_set2+train_set3\n",
    "    val_set = val_set1+val_set2+val_set3\n",
    "    test_set = ImageFolder(root=os.path.join('{}/test'.format(pacs_ver),domains[test_domain_idx]), transform = test_tf)\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_decay_epoch, gamma= lr_decay_gamma)  \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, optimizer, model, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T10:39:06.020977Z",
     "start_time": "2020-12-17T10:24:34.986484Z"
    },
    "code_folding": [
     11,
     63,
     68,
     75,
     82
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여부 True\n",
      "BYOL Training Start!\n",
      "BYOL Epoch: 1 [128/7478 (2%)],\t Loss: 3.863209\n",
      "BYOL Epoch: 1 [256/7478 (3%)],\t Loss: 2.559857\n",
      "BYOL Epoch: 1 [384/7478 (5%)],\t Loss: 2.181070\n",
      "BYOL Epoch: 1 [512/7478 (7%)],\t Loss: 2.037012\n",
      "BYOL Epoch: 1 [640/7478 (9%)],\t Loss: 1.977959\n",
      "BYOL Epoch: 1 [768/7478 (10%)],\t Loss: 1.921974\n",
      "BYOL Epoch: 1 [896/7478 (12%)],\t Loss: 1.909256\n",
      "BYOL Epoch: 1 [1024/7478 (14%)],\t Loss: 1.894120\n",
      "BYOL Epoch: 1 [1152/7478 (15%)],\t Loss: 1.876468\n",
      "BYOL Epoch: 1 [1280/7478 (17%)],\t Loss: 1.879770\n",
      "BYOL Epoch: 1 [1385/7478 (19%)],\t Loss: 1.868976\n",
      "BYOL Epoch: 1 [1513/7478 (20%)],\t Loss: 1.874537\n",
      "BYOL Epoch: 1 [1641/7478 (22%)],\t Loss: 1.875704\n",
      "BYOL Epoch: 1 [1769/7478 (24%)],\t Loss: 1.872128\n",
      "BYOL Epoch: 1 [1897/7478 (25%)],\t Loss: 1.870167\n",
      "BYOL Epoch: 1 [2025/7478 (27%)],\t Loss: 1.859357\n",
      "BYOL Epoch: 1 [2153/7478 (29%)],\t Loss: 1.862580\n",
      "BYOL Epoch: 1 [2281/7478 (31%)],\t Loss: 1.865765\n",
      "BYOL Epoch: 1 [2409/7478 (32%)],\t Loss: 1.875047\n",
      "BYOL Epoch: 1 [2537/7478 (34%)],\t Loss: 1.880400\n",
      "BYOL Epoch: 1 [2665/7478 (36%)],\t Loss: 1.894661\n",
      "BYOL Epoch: 1 [2690/7478 (36%)],\t Loss: 1.882034\n",
      "BYOL Epoch: 1 [2818/7478 (38%)],\t Loss: 1.910344\n",
      "BYOL Epoch: 1 [2946/7478 (39%)],\t Loss: 1.903945\n",
      "BYOL Epoch: 1 [3074/7478 (41%)],\t Loss: 1.925310\n",
      "BYOL Epoch: 1 [3202/7478 (43%)],\t Loss: 1.906423\n",
      "BYOL Epoch: 1 [3330/7478 (45%)],\t Loss: 1.926803\n",
      "BYOL Epoch: 1 [3458/7478 (46%)],\t Loss: 1.946237\n",
      "BYOL Epoch: 1 [3586/7478 (48%)],\t Loss: 1.949985\n",
      "BYOL Epoch: 1 [3714/7478 (50%)],\t Loss: 1.952285\n",
      "BYOL Epoch: 1 [3842/7478 (51%)],\t Loss: 1.950271\n",
      "BYOL Epoch: 1 [3934/7478 (53%)],\t Loss: 1.964585\n",
      "BYOL Epoch: 1 [4062/7478 (54%)],\t Loss: 1.896086\n",
      "BYOL Epoch: 1 [4190/7478 (56%)],\t Loss: 1.915414\n",
      "BYOL Epoch: 1 [4318/7478 (58%)],\t Loss: 1.920569\n",
      "BYOL Epoch: 1 [4446/7478 (59%)],\t Loss: 1.895330\n",
      "BYOL Epoch: 1 [4574/7478 (61%)],\t Loss: 1.902812\n",
      "BYOL Epoch: 1 [4702/7478 (63%)],\t Loss: 1.915602\n",
      "BYOL Epoch: 1 [4767/7478 (64%)],\t Loss: 1.906971\n",
      "BYOL Epoch: 1 [4895/7478 (65%)],\t Loss: 1.945639\n",
      "BYOL Epoch: 1 [5023/7478 (67%)],\t Loss: 2.047083\n",
      "BYOL Epoch: 1 [5151/7478 (69%)],\t Loss: 2.046941\n",
      "BYOL Epoch: 1 [5279/7478 (71%)],\t Loss: 2.023840\n",
      "BYOL Epoch: 1 [5407/7478 (72%)],\t Loss: 2.012242\n",
      "BYOL Epoch: 1 [5535/7478 (74%)],\t Loss: 2.086833\n",
      "BYOL Epoch: 1 [5663/7478 (76%)],\t Loss: 2.072541\n",
      "BYOL Epoch: 1 [5791/7478 (77%)],\t Loss: 1.926459\n",
      "BYOL Epoch: 1 [5919/7478 (79%)],\t Loss: 1.990308\n",
      "BYOL Epoch: 1 [5972/7478 (80%)],\t Loss: 2.068244\n",
      "BYOL Epoch: 1 [6100/7478 (82%)],\t Loss: 2.401573\n",
      "BYOL Epoch: 1 [6228/7478 (83%)],\t Loss: 2.401741\n",
      "BYOL Epoch: 1 [6356/7478 (85%)],\t Loss: 2.331515\n",
      "BYOL Epoch: 1 [6484/7478 (87%)],\t Loss: 2.297103\n",
      "BYOL Epoch: 1 [6567/7478 (88%)],\t Loss: 2.290108\n",
      "BYOL Epoch: 1 [6695/7478 (90%)],\t Loss: 2.252303\n",
      "BYOL Epoch: 1 [6823/7478 (91%)],\t Loss: 2.223378\n",
      "BYOL Epoch: 1 [6951/7478 (93%)],\t Loss: 2.206657\n",
      "BYOL Epoch: 1 [7079/7478 (95%)],\t Loss: 2.212622\n",
      "BYOL Epoch: 1 [7207/7478 (96%)],\t Loss: 2.190598\n",
      "BYOL Epoch: 1 [7335/7478 (98%)],\t Loss: 2.203840\n",
      "BYOL Epoch: 1 [7463/7478 (100%)],\t Loss: 2.204643\n",
      "BYOL Epoch: 1 [7478/7478 (100%)],\t Loss: 2.210459\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n",
      "Epoch: 1 [128/7478 (2%)],\tAccuracy: 14.8%,  \t Loss: 1.959178\n",
      "Epoch: 1 [256/7478 (3%)],\tAccuracy: 15.6%,  \t Loss: 2.005386\n",
      "Epoch: 1 [384/7478 (5%)],\tAccuracy: 24.2%,  \t Loss: 2.013628\n",
      "Epoch: 1 [512/7478 (7%)],\tAccuracy: 28.1%,  \t Loss: 1.977751\n",
      "Epoch: 1 [640/7478 (8%)],\tAccuracy: 20.3%,  \t Loss: 1.923596\n",
      "Epoch: 1 [768/7478 (10%)],\tAccuracy: 25.0%,  \t Loss: 1.988994\n",
      "Epoch: 1 [896/7478 (12%)],\tAccuracy: 25.8%,  \t Loss: 1.901466\n",
      "Epoch: 1 [1024/7478 (14%)],\tAccuracy: 28.1%,  \t Loss: 1.786933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 [1152/7478 (15%)],\tAccuracy: 29.7%,  \t Loss: 1.934658\n",
      "Epoch: 1 [1280/7478 (17%)],\tAccuracy: 26.6%,  \t Loss: 1.862675\n",
      "Epoch: 1 [1408/7478 (19%)],\tAccuracy: 32.8%,  \t Loss: 1.917690\n",
      "Epoch: 1 [1536/7478 (20%)],\tAccuracy: 39.1%,  \t Loss: 1.763749\n",
      "Epoch: 1 [1664/7478 (22%)],\tAccuracy: 27.3%,  \t Loss: 1.795865\n",
      "Epoch: 1 [1792/7478 (24%)],\tAccuracy: 26.6%,  \t Loss: 1.760242\n",
      "Epoch: 1 [1920/7478 (25%)],\tAccuracy: 40.6%,  \t Loss: 1.695852\n",
      "Epoch: 1 [2048/7478 (27%)],\tAccuracy: 30.5%,  \t Loss: 1.753803\n",
      "Epoch: 1 [2176/7478 (29%)],\tAccuracy: 35.9%,  \t Loss: 1.679090\n",
      "Epoch: 1 [2304/7478 (31%)],\tAccuracy: 28.1%,  \t Loss: 1.734833\n",
      "Epoch: 1 [2432/7478 (32%)],\tAccuracy: 32.8%,  \t Loss: 1.658628\n",
      "Epoch: 1 [2560/7478 (34%)],\tAccuracy: 35.2%,  \t Loss: 1.608387\n",
      "Epoch: 1 [2688/7478 (36%)],\tAccuracy: 39.8%,  \t Loss: 1.546030\n",
      "Epoch: 1 [2816/7478 (37%)],\tAccuracy: 41.4%,  \t Loss: 1.538763\n",
      "Epoch: 1 [2944/7478 (39%)],\tAccuracy: 43.0%,  \t Loss: 1.472282\n",
      "Epoch: 1 [3072/7478 (41%)],\tAccuracy: 49.2%,  \t Loss: 1.517703\n",
      "Epoch: 1 [3200/7478 (42%)],\tAccuracy: 47.7%,  \t Loss: 1.512829\n",
      "Epoch: 1 [3328/7478 (44%)],\tAccuracy: 40.6%,  \t Loss: 1.464215\n",
      "Epoch: 1 [3456/7478 (46%)],\tAccuracy: 48.4%,  \t Loss: 1.423572\n",
      "Epoch: 1 [3584/7478 (47%)],\tAccuracy: 46.1%,  \t Loss: 1.408630\n",
      "Epoch: 1 [3712/7478 (49%)],\tAccuracy: 47.7%,  \t Loss: 1.470995\n",
      "Epoch: 1 [3840/7478 (51%)],\tAccuracy: 52.3%,  \t Loss: 1.317719\n",
      "Epoch: 1 [3968/7478 (53%)],\tAccuracy: 53.1%,  \t Loss: 1.362983\n",
      "Epoch: 1 [4096/7478 (54%)],\tAccuracy: 58.6%,  \t Loss: 1.179556\n",
      "Epoch: 1 [4224/7478 (56%)],\tAccuracy: 48.4%,  \t Loss: 1.240245\n",
      "Epoch: 1 [4352/7478 (58%)],\tAccuracy: 58.6%,  \t Loss: 1.204358\n",
      "Epoch: 1 [4480/7478 (59%)],\tAccuracy: 50.8%,  \t Loss: 1.235188\n",
      "Epoch: 1 [4608/7478 (61%)],\tAccuracy: 54.7%,  \t Loss: 1.151219\n",
      "Epoch: 1 [4736/7478 (63%)],\tAccuracy: 58.6%,  \t Loss: 1.131780\n",
      "Epoch: 1 [4864/7478 (64%)],\tAccuracy: 58.6%,  \t Loss: 1.160146\n",
      "Epoch: 1 [4992/7478 (66%)],\tAccuracy: 60.2%,  \t Loss: 1.161245\n",
      "Epoch: 1 [5120/7478 (68%)],\tAccuracy: 64.8%,  \t Loss: 0.956995\n",
      "Epoch: 1 [5248/7478 (69%)],\tAccuracy: 70.3%,  \t Loss: 1.000907\n",
      "Epoch: 1 [5376/7478 (71%)],\tAccuracy: 66.4%,  \t Loss: 0.945759\n",
      "Epoch: 1 [5504/7478 (73%)],\tAccuracy: 65.6%,  \t Loss: 1.026714\n",
      "Epoch: 1 [5632/7478 (75%)],\tAccuracy: 71.1%,  \t Loss: 0.930740\n",
      "Epoch: 1 [5760/7478 (76%)],\tAccuracy: 58.6%,  \t Loss: 1.058205\n",
      "Epoch: 1 [5888/7478 (78%)],\tAccuracy: 67.2%,  \t Loss: 0.974840\n",
      "Epoch: 1 [6016/7478 (80%)],\tAccuracy: 70.3%,  \t Loss: 0.948511\n",
      "Epoch: 1 [6144/7478 (81%)],\tAccuracy: 65.6%,  \t Loss: 1.011205\n",
      "Epoch: 1 [6272/7478 (83%)],\tAccuracy: 68.8%,  \t Loss: 0.970685\n",
      "Epoch: 1 [6400/7478 (85%)],\tAccuracy: 75.0%,  \t Loss: 0.797486\n",
      "Epoch: 1 [6528/7478 (86%)],\tAccuracy: 64.8%,  \t Loss: 0.978281\n",
      "Epoch: 1 [6656/7478 (88%)],\tAccuracy: 69.5%,  \t Loss: 0.926460\n",
      "Epoch: 1 [6784/7478 (90%)],\tAccuracy: 72.7%,  \t Loss: 0.856671\n",
      "Epoch: 1 [6912/7478 (92%)],\tAccuracy: 64.8%,  \t Loss: 0.886928\n",
      "Epoch: 1 [7040/7478 (93%)],\tAccuracy: 76.6%,  \t Loss: 0.739005\n",
      "Epoch: 1 [7168/7478 (95%)],\tAccuracy: 75.0%,  \t Loss: 0.725921\n",
      "Epoch: 1 [7296/7478 (97%)],\tAccuracy: 69.5%,  \t Loss: 0.852884\n",
      "Epoch: 1 [7424/7478 (98%)],\tAccuracy: 70.3%,  \t Loss: 0.761148\n",
      "Epoch: 1 [7478/7478 (100%)],\tAccuracy: 74.1%,  \t Loss: 0.744374\n",
      "Validation batch 0/7loss_val: 5.188102722167969 843\n",
      "acc_val: 633 843\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0062\n",
      "Avg acc (val): 0.7509\n",
      "\n",
      "Best Weights Updated!\n",
      "Best validation acc: 0.7509\n",
      "Test:  [128/1670 (7%)],\tAccuracy: 43.8%,  \t Loss: 1.582844\n",
      "Test:  [256/1670 (14%)],\tAccuracy: 48.4%,  \t Loss: 1.365169\n",
      "Test:  [384/1670 (21%)],\tAccuracy: 50.0%,  \t Loss: 1.119367\n",
      "Test:  [512/1670 (29%)],\tAccuracy: 49.2%,  \t Loss: 1.647633\n",
      "Test:  [640/1670 (36%)],\tAccuracy: 52.0%,  \t Loss: 1.227173\n",
      "Test:  [768/1670 (43%)],\tAccuracy: 55.6%,  \t Loss: 0.838680\n",
      "Test:  [896/1670 (50%)],\tAccuracy: 54.5%,  \t Loss: 1.440200\n",
      "Test:  [1024/1670 (57%)],\tAccuracy: 58.1%,  \t Loss: 0.455584\n",
      "Test:  [1152/1670 (64%)],\tAccuracy: 62.8%,  \t Loss: 0.001719\n",
      "Test:  [1280/1670 (71%)],\tAccuracy: 66.4%,  \t Loss: 0.114067\n",
      "Test:  [1408/1670 (79%)],\tAccuracy: 69.4%,  \t Loss: 0.273613\n",
      "Test:  [1536/1670 (86%)],\tAccuracy: 71.8%,  \t Loss: 0.248198\n",
      "Test:  [1664/1670 (93%)],\tAccuracy: 73.9%,  \t Loss: 0.252180\n",
      "Test:  [1670/1670 (100%)],\tAccuracy: 74.0%,  \t Loss: 0.234593\n",
      "74.01\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAC8CAYAAAAHBLanAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5wcdZnv8c+XBBQhoBISRC4CAsplMSQHRUCGhSjgdUVuclk8KxhYEA+gK4hHQMFjQCByEZJVA3HdBcEbiiaoDHIVCAiGiwQSrgmBAK9AAoEQnvPHrzp0aqq7q2empzsz3/frVa+ernrqV0/PzK/7qapfVSsiMDMzs6FttXYnYGZmZu3ngsDMzMxcEJiZmZkLAjMzM8MFgZmZmeGCwMzMzHBBYGZmZrggMDMzM1wQWD+R9E5JIenadudiNlRJ+nnWD69rdy626nFBYP1lx+zx7rZmYTZESeoC9gPmAh9obza2KnJBYP2lUhDc1dYszIYgScOAScBPgauAkZLe3d6sypG0mqQ12p2HuSCw/lO6IJC0paSpkp6S9JqkhyWdKEm5uHUkfUPSvZIWSXpR0v2SLmwmxmwI+BLwXuBk4O/ZvJpHCSSNlHSWpPskvSLpeUl/kfTpZuMk/VnS4wXb2CQ7ffGtqnnfy+ZtLekHkp4CXgfGZqcdz5B0m6RnJb0s6UFJ/yGpx2dVo9wkXZJta8OCdbfO3nsmNfrFDiXD252ADRo7Ai9ExNx6QZI+CvwSeAq4EHgB+ARwDrAecEoW9xbgRmBT4CfA/cDbgO2BrcrGmA12kt4JfBuYGBFPSaouCH5XEL8dcB2wLjAFuBcYDewDvA/4dTNxwBiguyC1sdlj9WnEMcArwDXAQ8B3gXWAWcDHgf2znC8D1gAOBP4fEMDEJl/DraRCaSfgV7nczgNeBE4ryHvoighPnvo0ASOAN4A/NYjbDFhM+hB/W27ZbcDSynzSG0MAH63TXsMYT54G+wRcBDxZ1XfeAiwDfl4Q+3bgCeAxYIuC5W9tMm7zrA+eWhDznWzZxlXzns3mfa0gfq2CeasDjwA39eI1bJ1t66zc8o9n849p99+u0yafMrD+MAYQjU8XnErag/9iRLycW9ZNeiPbNHv+juxxp6LDhU3EmA1akrYn7QWfXOlTEfEqae+76JTBycBGwOcj4pH8wohY2mRc5SjAzIJtjQWei4gnslw3AkYCN0fExHxwRCzJ4pSdChxJOgLwDOm9oanXEBH/AJ4nHSEga3t14FzSEYlLC3Ie0vwmav2h8qZQsyDIPrD/Bbg+66g9QrLHJdnjVcA9pEOh8yRNkfSJ3Ad/mRizwWwSMAe4TdJ7KxPwOLCFpBGVwGyMzqHAbRFxc60Gy8ZlKmOHahUEdxfEXl5juwdI6ia9BywiHU14FvgQMLsXuUE68jiuanzS8aTTiV+JiOUl1h9S/MZp/aHMgMKNSHv099dYvh1pPMETABHxPOkNZW/gCmA86bzjTZURyWVizAYrSfsDewBbko4IzK6a9iYV2f9UtcooYEPSh2Q9ZeMg9f0nI+KZXG5bAusDf6uaPSZ7/HPBa5lI6sNLgBOBT5L684QspFJYNJMbWdy6wNaSRgHfBH4VEX8quf6Q4kGF1h92JI0NmF0nJrLH1/ILJG1M6vzTIjvJB5BV8NOB6ZJOAKaS9g52AO4oG2M22EhaEzibNLBuckHIB4BvZI+VPel1s8coiK9WNg5gG+C+gvmfzx7zAwoXkcYErJCdSjgJ+FlEHJJb1pX9WNnZaCY3SAMLIZ02+Ajp1MOJJdcdclwQWJ9Iehtp8M6tEfFGndAnSW8Gu+fWXxOYBiwnjThG0vrAwnxxIGk56Y3gqTIx/fH6zDrU14BNgE9FxL35hZJm8WZBUPEkqSDfS9Kw6kPm2SH1YRHxehNxAGsBa+e2vTPw9expviC4q7rPZjYmHc14MNfObqRCAd4sCJrJDeCvpAHP/wbsCpwdEXOwQi4IrK92AIYBb5X09YLliyPiwogISWcCEyX9Fvgtqdr/36SBhAdExMPZOucAu0r6NfAw6dTWx0iXJ54dEfMkXdYoplUv2KydJG0C/Afwi6JiIPMIqcheURBExMuSfkg6j36TpJ+TDtFvCXw2i32xbFzW7G3APpJ+RBrP8wHSKP7ZwBakUxmVSyM3Aa4syHUWafDfSdn4n2dIe/R7ZvNfjYgXmnkNVa/5JUn3k44OPA2cWedXa+2+zMHTqj0B/07aI6813VAVK+CrpDer14D5wM+AbXNtHk66FvlJ4NUs7k/Ap5uJ8eRpME6kc+1vANs3iJtNuuZ/eNW8YaTz8neRPjhfJH2Qn5Zbt2zcpsAfSKcMF5DuB7Ix6UP+tqq4PbP3g4Nr5Lozqbh4GZhHugLg3cBLwNW9ya0q/kfZto9o99+u0ydlvzAzM7NBJbvM8EGyyw/DH3h1+ZSBmZkNVieRboh2iIuBxlwQmJnZoJGNV/gY6ZLLrwLnRkTZyxSHNBcEZmY2mHyMNDbpGdJ3FhQNdrYCHkNgZmZmvlOhmZmZDfFTBiNHjoz3vOc9A7KtJUuWsNZaaw3ItspyTuU4J5g5c+bCiFh/wDbYpIHsy+D/ibKcU2Md1Zfbfd1jO6exY8fGQLn++usHbFtlOadynFMEcGd0QJ+tNQ1kX47w/0RZzqmxTurLPmVgZmZmLgjMzMzMBYGZmZnhgsDMzMxwQWBmZma4IDAzMzNcEJiZmRkuCMzMzAwXBGZmZkYTBYGkYyTNlbRU0kxJuzWI3z2LWyppjqQJvWlT0k6SrpO0WNJLkm6RNLIg7q2S7pEUksaVfV1mZmZWsiCQdCAwCTgLGAPcAvxe0iY14jcDrs3ixgDfBS6QtF8zbUr6IDAD6AY+BIwFzgGWFWz2HODJMq/HzPqumZ0ESVOzYj0/LcnFfV7S3yS9LOlpST+VtEHrX42ZlT1CcAIwNSKmRMQDEXEcMB84ukb8BGBeRByXxU8BLgNOarLN84CLIuLMiJgVEQ9FxC8iYlH1xiR9Gtgj176ZtUizOwnA8cC7ctMc4MqqNncBppHeK7YFPgNsA/xXa16FmVVrWBBIWoO0Zz4jt2gG8OEaq+1cED8dGCdp9TJtShqVtTNf0k2SFki6UdKeufw2An4IHAK80uj1mFm/aGonISIWRcTTlQnYAtgcmFIVtjPwZEScFxFzI+I24ALgg619KWYG5b7+eCQwDFiQm78A2KvGOhsAfyyIH561pxJtbp49ng58Fbgb2B+YLmlsRNwjaRhp7+H7EfE3Se9p9GIkHQUcBTB69Gi6u7sbrdIvFi9ePGDbKss5leOcVlZV0J+TW1RvJyHvSOC+iLilat7NwFmSPgn8FlgPOIh0+tHMWqxMQVARuecqmNcovjJfdWIq8ypHLy6NiB9nP98tqYt0SuJo4BTSeIJzGyW/IqmIycBkgHHjxkVXV1fZVfuku7ubgdpWWc6pHOfUQ292ElaQtC6puD+len5E3CrpYFKRvybp/ek64F9rtNOW4h5cJJblnBrrpHzKFAQLgeWkvf5qo+j5hlDxdI3414HnSB/8jdqcnz3en4t5AKicp9wT2A1YJqk65jZJV0TEITXyM7O+a3YnoeJQUkExbaWVpW2AHwDfJp1ifBdwNnApcHiPjbepuIe2F2SFnFM5nZZTJ+XTsCCIiNckzQTGAz+vWjQeuLrGareSBgRVGw/cGRHLAEq0+SgwD9g6185WwN+zn78ArFW1bEPSG8khpMOPZtb/erOTUO1I4OqIeD43/2Tg9og4O3t+b3YVwo2SvhERT/QlaTOrr+wpg3OBaZJuJ33QTiB9+F4CIOlygIioVPGXAMdKOp9U3e8CHAEcXLbNiAhJZwOnS7qXNIbgANLlh8dmMXOrk5S0OPvxkYjwJYhmLdDLnQQg3VcE2AH4SsHit5EKjWqV58LMWqpUQRARV0haDziVdBhvFrBvRDyWhWySi58raV/SZYNHk/b0vxwRVzfRJhFxfjaA6fukAUb3AftExD29erVm1l+a3UmoOAqYDdxQ0OY1wBRJR/PmKYPzgbsi4vFWvAgze1PpQYURcTFwcY1lXQXzbgB27G2bVTETgYklc3wU70mYtVyzOwkAkkaQrho4IyJ6jDWIiKlZzLGknYBFwPXA11rzKsysWjNXGZiZrdCLnYSXgLUbtHkB6d4DZjbA/OVGZmZm5oLAzMzMXBCYmZkZLgjMzMwMFwRmZmaGCwIzMzPDBYGZmZnhgsDMzMxwQWBmZma4IDAzMzNcEJiZmRkuCMzMzAwXBGZmZoYLAjMzM8MFgZmZmeGCwMx6SdIxkuZKWipppqTd6sROlRQF05Jc3BqSzsjafVXS45K+3PpXY2bD252Ama16JB0ITAKOAW7KHn8vaZuIeLxgleOBr+fm3Qz8JTfvv4GNgaOA2cBoYM1+TN3ManBBYGa9cQIwNSKmZM+Pk7Q3cDRwcj44IhYBiyrPJe0CbA4cVjXvo8BewBYRsTCb/WhLsjezHnzKwMyaImkNYCwwI7doBvDhks0cCdwXEbdUzfsMcAdwgqQnJc2W9ANJa/c5aTNryEcIzKxZI4FhwILc/AWkPfy6JK0L7A+cklu0ObAr8CqwH/B24AJgQ+BzBe0cRTq1wOjRo+nu7m7mNfTJ4sWLB3R7ZTincjotp07Kp3RBIOkY4KvAu4D7gK9ExI114ncHzgW2BeYBEyPikmbblLQTcCawMxDA34FPRcRCSe8BvgnskbUxH7gCOCMiXin72sysVyL3XAXzihxKKiim5eavlq3/+ewUA5KOBaZLGh0RKxUgETEZmAwwbty46OrqavoF9FZ3dzcDub0ynFM5nZZTJ+VT6pRB1QCis4AxwC2kAUSb1IjfDLg2ixsDfBe4QNJ+zbQp6YOkw5DdwIdIhynPAZZlIe8jvbEcTSo8jgMOz9o1s9ZYCCwHNsjNH0XPowZFjgSujojnc/PnA09VioHMA9lj4XuNmfWfsmMIVgwgiogHIuI4Uuc9ukb8BGBeRByXxU8BLgNOarLN84CLIuLMiJgVEQ9FxC8qbxgR8YeIOCIipkfEnIj4Helown6YWUtExGvATGB8btF4UmFfU3bEbwdgSsHim4ENc2MGtsoeH+tdtmZWVsOCoJcDiHYuiJ8OjJO0epk2JY3K2pkv6SZJCyTdKGnPBimvA7zQIMbM+uZc4AhJX5T0fkmTSOf6LwGQdLmkywvWq1xOeEPBsp8BzwE/kbRtdiXCJOCqiHimJa/CzFYoM4agNwOINgD+WBA/PGtPJdrcPHs8nTTO4G7SQKTpksZGxD35jWanG04inYYo1K6BSJ00cKTCOZXjnHqKiCskrQecShq/MwvYNyIqe/I9DvFLGgEcRBrj02OsQUQslrQXaSDhHaTC/lf0vH+BmbVAM1cZNDuAqCi+Ml91YirzKkcvLo2IH2c/3y2pi3RKYqXTFZJGk45CXEc61VCcVJsGInXSwJEK51SOcyoWERcDF9dY1lUw7yWg7iWEEfEP4KP9kZ+ZNadMQdCbAURP14h/nXRIUCXanJ893p+LeYDc3oekDYA/k/ZSDiva+zAzM7PaGo4h6OUAolvpeTphPHBnRCwr2eajpMsVt87FbEXVACNJ7yJdhfAAcHBEvF7/FZmZmVle2VMG5wLTJN1OGgk8gdwAIoCIODyLvwQ4VtL5wKXALsARwMFl24yIkHQ2cLqke0ljCA4gXX54bLbdDUnFwDzgK8BIqXI2gmcjYnnJ12dmZjaklSoImh1AFBFzJe1LOpd/NOkD+8sRcXUTbRIR52dXJHwfWI9086J9qgYUfhTYMpvyX6iyGb4PupmZWSmlBxX2YgDRDcCOvW2zKmYiMLHGsqnA1Hrrm5mZWWP+ciMzMzNzQWBmZmYuCMzMzAwXBGZmZoYLAjMzM8MFgZmZmeGCwMzMzHBBYGZmZrggMDMzM1wQmJmZGS4IzKyXJB0jaa6kpZJmStqtTuxUSVEwLakRv6uk1yXNat0rMLNqLgjMrGmSDgQmAWcBY0hfW/57SZvUWOV40peYVU9zgCsL2n4HcDnwp/7P3MxqcUFgZr1xAjA1IqZExAMRcRwwn/Ttpj1ExKKIeLoyAVsAmwNTCsJ/BFwG3Nqi3M2sgAsCM2tK9pXkY4EZuUUzgA+XbOZI4L6IuCXX9jHABsB3+pqnmTXHBYGZNWskMAxYkJu/gPRhXpekdYH9yR0dkLQ98C3gkIhY3j+pmllZw9udgJmtsiL3XAXzihxKKiimrVhRegvwP8BJETG3zMYlHQUcBTB69Gi6u7vLrNYvFi9ePKDbK8M5ldNpOXVSPi4IzKxZC4Hl9DwaMIqeRw2KHAlcHRHPV817F7AN8BNJP8nmrQZI0uvAvhGx0imKiJgMTAYYN25cdHV1Nfs6eq27u5uB3F4ZzqmcTsupk/LxKQMza0pEvAbMBMbnFo0nXW1Qk6SdgB3oOZjwKWB74ANV0yXAw9nPdds1s77zEQIz641zgWmSbgduBiYAG5I+xJF0OUBEHJ5b7yhgNnBD9cyIWAasdM8BSc8Ar0aE70VgNgBcEJhZ0yLiCknrAaeSDvfPIh3WfywL6XE/AkkjgIOAMyKizFgDMxtALgjMrFci4mLg4hrLugrmvQSs3UT7pwGn9S47M2tW6TEEzdymNIvfPYtbKmmOpAm9aVPSTpKuk7RY0kuSbpE0smr5OyRNk7Qom6ZJenvZ12VmZmYlC4Jmb1MqaTPg2ixuDPBd4AJJ+zXTpqQPkm520g18iHQzlHOAZVWb+xmwI7APsHf28zTMzMystLKnDFbcpjR7fpykvUm3KT25IH4CMC+7nSnAA9mH+0nA1U20eR5wUUScWdX2Q5UfJL2fVATsWrnjmaQvATdK2joi/lHy9ZmZmQ1pDY8Q9PI2pTsXxE8HxklavUybkkZl7cyXdJOkBZJulLRnbjuLWfmSpJuBJXVyMzMzs5wyRwjq3aZ0rxrrbAD8sSB+eNaeSrS5efZ4OvBV4G7S7U6nSxobEfdk23m2esRyRER2uVLhLVTbdXezTrobVYVzKsc5mdlQ0MxVBs3eprQovjJfdWIq8ypHLy6NiB9nP98tqYt0SqLyrWpFOdTMrV13N+uku1FVOKdynJOZDQVlCoLe3Kb06RrxrwPPkT6wG7U5P3u8PxfzAG9e4/w0MEqSKkcJJAlYv05uZmZmltNwDEEvb1N6Kz1PJ4wH7oyIZSXbfBSYB2ydi9kKqNz85FbSdc07Vy3fGVirTm5mZmaWU/aUQbO3Kb0EOFbS+cClwC7AEcDBZdvMxgKcDZwu6V7SGIIDSJcfHpvFPCDpD8Clko4kHXm4FPitrzAwMzMrr1RB0OxtSiNirqR9SZcNHk3a0/9yRFzdRJtExPnZFQnfB9YD7gP2yQYUVhwC/IA3r1j4DVnBYGZmZuWUHlTYi9uU3kC6SVCv2qyKmQhMrLP8edL3q5uZmVkv+euPzczMzAWBmZmZuSAwMzMzXBCYmZkZLgjMzMwMFwRm1kuSjpE0V9JSSTMl7VYndqqkKJiWVMV8VtIMSc9KeknSXyV9amBejZm5IDCzpkk6EJgEnAWMId0Z9PeSNqmxyvGk+41UT3OAK6tidgf+DHw8a/Na4Jf1Cg0z6z/NfLmRmVnFCcDUiJiSPT9O0t6kG5GdnA+OiEXAospzSbuQvtH0sKqY43OrnS7p48BngBv7N30zy/MRAjNrSnb30LG8eXfQihnAh0s2cyRwX0Q0+s6REcALzWVoZr3hIwRm1qyRwDB6fqPoAnp+qVkPktYF9gdOaRD378BGwLQay48CjgIYPXo03d3djTbdbxYvXjyg2yvDOZXTaTl1Uj4uCMystyL3XAXzihxKKigKP+gBJO0HnA0cVP39JittPGIyMBlg3Lhx0dXVVWLT/aO7u5uB3F4ZzqmcTsupk/LxKQMza9ZCYDmwQW7+KHoeNShyJHB19j0kPWTFwDTg8Ij4TV8SNbPyXBCYWVMi4jVgJjA+t2g86WqDmiTtBOwATKmx/ADgp8AREXFV37M1s7J8ysDMeuNcYJqk24GbgQnAhsAlAJIuB4iIw3PrHQXMBm7INyjpINKRgZOAv0iqHIF4rdbRBDPrPy4IzKxpEXGFpPWAU0n3FJgF7Ft1vr/H/QgkjQAOAs6IiKKxBhNI70nnZ1PFDUBX/2VvZkVcEJhZr0TExcDFNZZ1Fcx7CVi7Tns91jGzgeMxBGZmZuaCwMzMzFwQmJmZGS4IzMzMDBcEZmZmhgsCMzMzwwWBmZmZASq+P8jQIOlZoPCLU1pgJOke8J3EOZXjnGDTiFh/ALfXlAHuy+D/ibKcU2Md05eHdEEwkCTdGRHj2p1HNedUjnOyvE78/Tuncjotp07Kx6cMzMzMzAWBmZmZuSAYSJPbnUAB51SOc7K8Tvz9O6dyOi2njsnHYwjMzMzMRwjMzMzMBYGZmZnhgqDfSHqLpAskLZS0RNJvJG1UYr1jJM2VtFTSTEm71YiTpD9ICkmfa0c+kt6ZtfmgpFckPSHph5LW6+vrq4rfPYtbKmmOpAl9bbOV+Ug6WdIdkl6U9KykayRtVzafVuSUiz0l+5+5sJmchrJO68utyqnZ/txpfbkVOQ35/hwRnvphAn4IzAPGAzsC3cDfgGF11jkQWAYcCbwfuABYDGxSEHsS8DsggM+1Ix9gO+AXwKeA9wK7A/cBM/r6+rL4zYAlWdz7s/WWAfv1ts0ByGc68IXsd7M98EvgaeCdJf9v+j2nqtgPAXOBe4AL291HVpWp0/pyq3Jqpj93Wl9uYU5Duj+3vfMNhglYF3gNOKRq3sbAG8DH6qz3V2BKbt5s4Lu5eeOAJ4BRZd5EWp1Pbvm+Wbvr9LU94HvA7Ny8/wRu7UuOrcynYJ21geXAJ0v+77Qkp+x/4BHgn0kfHi4Iyv09OqovD0ROueWF/bnT+nKrcipYZ0j1Z58y6B9jgdWBGZUZEfEE8ADw4aIVJK2RrTcjt2hG9TqSRgD/DXwpIp5pdz4F1gFeBV7uh/Z2LoifDoyTtHofcmxJPjXWGUE6FfdCvXwGIKfJwFUR8edGedhKOq0vtzSnAj36c6f15VblVGOdIdWfXRD0jw1IVWT+ftQLsmVFRgLDsph661wC/CEiru2QfFaQ9Hbg26SK+PW+tpfNL4ofnrXXmzZbmU+RSaRDubc2yKdlOUk6knQI+JslcrCVdVpfbnVOK9Tpz53Wl1uVU5Eh1Z+Ht3oDqzJJ3wG+0SBsj3pNkA4L1pNfvmIdSYcBO5AOM1byAfi5pAHPZ6WZ0lrANcBTwNf62l6D+Mp81Ykpe0ON/sxn5QXSucCuwK4RsbxkPv2ak6StgbOA3SLitSZyGNQ6rS9XqdeXW5rTSjPL9edO68v9ndPKC4Zgf3ZBUN/5wE8bxDxOGuwxjFTRPVu1bBTwlxrrLSRV/fnKcRRvVox7AtsAi3NvGm+QqtZDBjgfACStDVT2cj4REUv70l6Vp2vEvw48R+oozbbZynxWkHQecBCwR0TMaZBLK3Pam/R3n1X1PzMM+Eg2enmtiHi1ZH6DyarYl1udE1CqP3daX25VTisM2f7cioEJQ23izUE/n6+atxHlBv1Mzs17iGwACvBu0mjX6imA/wNsPtD5ZM9HADcBNwMjGvxeGraXW/Y94B+5eZPpORCpdJutziebN4nU4d/fi/+dfs0JeHvB/8wdwM+ynzXQ/WNVmjqtL7cyp+x5qf7caX25VTll84Zsf257BxwsE+myoKeAvYAxwPXkLgsCHgSOrXp+YNbRv0i65GQS6RKVTetsp+zI5H7PJ3vzuJV0adKWpMq2Mq1RkEOj9i4HLq+Kr1yCc34W/8Vs/fylSk39zlqcz0XAi6TRv9W/j7VL/t/0e04F2+jGVxmssn25VTk10587rS+3MKch3Z/b3vkGywS8lXQt6XOkEbrXABvnYgI4LTfvGOBR0sjemcBHGmynbEHQ7/kAXdk6RVNXjTzqtdcNdOfidwfuyuLnAhOaabPE76Vf86nz+zitXTkVtN+yN5DBOHVaX25VTs32507ry63Iaaj3Z3+5kZmZmfmyQzMzM3NBYGZmZrggMDMzM1wQmJmZGS4IzMzMDBcEZmZmhgsCMzMzwwWBmZmZ4YLAVnGStpEUksa3Oxcz6z335fZzQWCruh2zxzvbmoWZ9ZX7cpu5ILBV3VjgkYh4od2JmFmfuC+3mQsCK0XJv0m6XdLLkp6UdJ6kNatibpd0paQzJD0iaamkeyXtWdDeapK+nC1/RdIcSadJWj0Xt7+kGyS9KGmxpDskfbwqZCxwh6TDJN2VtXW/pD1y7XxQ0m8kzc/yekzSZf39ezLrdO7LVsvwdidgq4z/BA4BzgW+AWwFnEX6FrajJQ0Htge2BUaSvud9GHAm8AtJW0TEQgBJw4ArSV8x+m3gbtLhwjOBtwAnZ3HnZO1cCnyf9K1jewHrZMsFfADYFHgH8B1gGXA26WtGN87i/hdwI/BfpK8XfYX0da/b9fcvyWwV4L5sxVrxFYqeBtcEHE7qwJ/NzT+R9JWdw4B/ymJuYOXvaN89m/8vufWWAWNz7V0KPJf9fBANvh4W2DqLuTo3/5hs/prZ80nAQ+3+PXry1O7JfdlTvcmnDKyMU4G/AL+RNLwyAfcDawAbkg73AZwSEcur1n0we1wPVuwJfAW4MiJm5rbzMPBOSW8FTgeuiYir6uS1Ypu5+SOBFyPilez5M8B7JZ0jafsSr9dssHJftpp8ysDqkrQZ6ZDclqQ9gSKLSIcJ50XEzbllG2aPT2aPWwEbAdcWtLMx8EK2zlakw4b17Ag8GhH/yM0fA9xb9fwc0pvdYcCJkh4GJkXEhQ3aNxs03JetERcE1si7s8cvALMKlr8RES9K2hF4qmD5gcDLpPN+AOtnj09XB2V7G/8M/Ik333jmNchtLHBXwfwxwK8rTyLiVeBbwLckbQOcAVwg6a6IuKXBNswGC/dlq8sFgTVSeWN4NSIKrw+WtBqwA7BE0vCIeD2bvyHpHOCFEbEkC38se3wv6Q2j4gukQUxH8+abx7a5mOptivRmcU5u/jtIA5PuLlovIu6XdD6wH/7/t6HFfdnq8i/RGnkUuB6YJGkUcA/wNmAzYDzwWZEr2MoAAAE8SURBVOB9wFrA88BUST8hHUr8v6Tzjt+qNBYRT0iaQarwXyYdfvwYcAJwakTcmL1B3AScnn7kXmA0sC9wZkQ8BGwBrEvPvYox2eNdAJIuAtYE/kh6Q9yCNLL6diB/SNRsMHsU92Wrp92jGj11/kQaRPQDYA6wFFhAGoF8XLb8UNJI4O2A35IOKy4ALgBG1GhvKulQ42JSZ86Peh4FTAEeJ41+fhyYBqyeLT8w2+YGufVOzHIcnj0/Lmt/IekSpQdJhxl75OXJ02Cf3Jc91ZuU/aLNek3SeaRLijZudy5m1nvuy0ObLzu0/rAjkL/syMxWPe7LQ5gLAuuTqjuM+U3EbBXmvmw+ZWBmZmY+QmBmZmYuCMzMzAwXBGZmZoYLAjMzM8MFgZmZmeGCwMzMzHBBYGZmZrggMDMzM+D/Ax3LwZwmTY7UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_model_setting(model_settings,used_model,domains,dataset,save_name)\n",
    "\n",
    "for i in range(1,number_of_tests+1):\n",
    "    try_check = i\n",
    "    \n",
    "    for test_idx in [0,1,2,3]:\n",
    "        \n",
    "        ##########################\n",
    "        #### Training Setting ####\n",
    "        ##########################\n",
    "        if training_setting=='classic':\n",
    "            train_loader, val_loader, test_loader, optimizer, model, lr_scheduler = classic_setting(\n",
    "                test_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model, pacs_ver\n",
    "            )\n",
    "        elif training_setting=='di':\n",
    "            train_loader, val_loader, test_loader, optimizer, model, lr_scheduler = di_setting(\n",
    "                test_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model, pacs_ver\n",
    "            )\n",
    "        elif training_setting=='cc':\n",
    "            train_loader_stage1,train_loader_stage2, val_loader_stage1, val_loader_stage2, test_loader, optimizer, model, lr_scheduler = cc_setting(\n",
    "                test_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model, pacs_ver\n",
    "            )\n",
    "        elif training_setting=='fm':\n",
    "            train_loader_stage1, train_loader_stage2,val_loader_stage1, val_loader_stage2, test_loader, optimizer, fm_optimizer, model, mixer, lr_scheduler = fm_setting(\n",
    "                test_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model, pacs_ver\n",
    "            )\n",
    "        elif training_setting=='byol':\n",
    "            model,train_loaders=byol_setting(test_idx, domains, byol_batch_size, is_pretrained)\n",
    "            \n",
    "            learner = BYOL(\n",
    "            model,\n",
    "            image_size = byol_image_size,\n",
    "            hidden_layer = 'avgpool'\n",
    "            )\n",
    "            \n",
    "            optimizer=torch.optim.Adam(learner.parameters(), lr=byol_lr)\n",
    "            \n",
    "            #BYOL training\n",
    "            byol_training(device, byol_epochs,learner,train_loaders,optimizer)\n",
    "\n",
    "            #fine-tune용 dataloader\n",
    "            train_loader, val_loader, test_loader, optimizer, model, lr_scheduler = byol_classic_setting(model,\n",
    "                test_idx, domains, batch_size, is_pretrained, train_tf, test_tf, used_model, pacs_ver\n",
    "            )\n",
    "            \n",
    "#             torch.save(resnet.state_dict(), './improved-net_'+domains[test_domain_idx]+'.pt')\n",
    "            \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        \n",
    "        save_dir = save_route(test_idx, domains, dataset, save_name, used_model)\n",
    "        try:\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "        except:\n",
    "            print('Error : Creating directory. '+ save_dir)\n",
    "        \n",
    "                \n",
    "        ##########################\n",
    "        ####     Training     ####\n",
    "        ##########################\n",
    "        \n",
    "        if training_setting=='classic':\n",
    "            model, losses, accuracies = classic_training(\n",
    "                device, epochs, model,optimizer, criterion, train_loader, val_loader, lr_scheduler\n",
    "            )\n",
    "            test_accuracy,_,__=classic_test(device, model,criterion, test_loader,used_model, save_dir, try_check)\n",
    "        elif training_setting=='di':\n",
    "            model, losses, accuracies = di_training(\n",
    "                device, epochs, model,optimizer, criterion, train_loader, val_loader,\n",
    "                lr_scheduler, is_d_vec=is_domain_vec, gamma_d_loss=gamma_d_loss, is_dc = is_dc, \n",
    "                entropy_weight = entropy_weight\n",
    "            )\n",
    "            di_test(device, model,criterion, test_loader,used_model, save_dir, try_check,is_d_vec=is_domain_vec, is_dc = is_dc)\n",
    "        elif training_setting=='cc':\n",
    "            model, losses, accuracies = cc_training(\n",
    "                device, epochs, model,optimizer, criterion, train_loader_stage1,train_loader_stage2, val_loader_stage1, val_loader_stage2,\n",
    "                lr_scheduler, is_d_vec=is_domain_vec, gamma_d_loss=gamma_d_loss, is_dc = is_dc, \n",
    "                entropy_weight = entropy_weight\n",
    "            )\n",
    "            di_test(device, model,criterion, test_loader,used_model, save_dir, try_check,is_d_vec=is_domain_vec, is_dc = is_dc)\n",
    "        elif training_setting=='fm':\n",
    "            model, losses, accuracies = fm_training(\n",
    "                device, epochs, model, mixer, optimizer, fm_optimizer, criterion, train_loader_stage1, train_loader_stage2, \n",
    "                val_loader_stage1, val_loader_stage2, lr_scheduler, is_d_vec=is_domain_vec, gamma_d_loss=gamma_d_loss, is_dc = is_dc, \n",
    "                entropy_weight = entropy_weight\n",
    "            )\n",
    "            test_accuracy,_,__=di_test(device, model,criterion, test_loader, used_model, save_dir, try_check,is_d_vec=is_domain_vec, is_dc = is_dc)\n",
    "        elif training_setting=='byol':\n",
    "            if is_byol_conv_freeze:\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad=False\n",
    "            \n",
    "            num_ftrs = model.fc.in_features\n",
    "            model.fc = torch.nn.Linear(num_ftrs,len(classes))\n",
    "            model = model.to(device)\n",
    "            print(model)\n",
    "            \n",
    "            model, losses, accuracies = classic_training(\n",
    "                device, epochs, model,optimizer, criterion, train_loader, val_loader, lr_scheduler\n",
    "            )\n",
    "            test_accuracy,_,__=classic_test(device, model,criterion, test_loader,used_model, save_dir, try_check)\n",
    "            \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        \n",
    "        #total result 한번에 보게 결과들 저장하는 텍스트파일    \n",
    "        total_result_text_path=os.path.join(save_dir,\"total_result.txt\")\n",
    "        with open(total_result_text_path,\"a\") as f:\n",
    "            print(test_accuracy)\n",
    "            f.write(str(test_accuracy)+\"\\n\")\n",
    "            \n",
    "            \n",
    "        plotting(losses, accuracies, used_model, save_dir, is_pretrained, try_check)\n",
    "        save_model(model, used_model, save_dir, is_pretrained, try_check)\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.4px",
    "left": "954px",
    "right": "20px",
    "top": "239px",
    "width": "503px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
